{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple clean working image captioning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bTrMiDYtfoeh"
      ],
      "mount_file_id": "15o3yQNevgqMIc1xf-GU_nwO2ptjX5jGP",
      "authorship_tag": "ABX9TyMppRxBjJF0iJtDCtWBICDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gadm21/AI/blob/master/simple_clean_image_captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTrMiDYtfoeh",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORT & DEFINE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THzwSdAfdUZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture \n",
        "\n",
        "from tensorflow import keras \n",
        "import keras.layers as L \n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam \n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.utils import to_categorical\n",
        "from  keras.applications import InceptionV3 \n",
        "from  keras.applications.inception_v3 import preprocess_input \n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np \n",
        "import cv2 \n",
        "import pickle \n",
        "import random \n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "PAD = \"#PAD#\"\n",
        "UNK = \"#UNK#\" \n",
        "START = \"#START#\" \n",
        "END = \"#END#\"\n",
        "\n",
        "NUM_WORDS = 5000\n",
        "SENTENCE_LEN = 20\n",
        "WORD_EMBED_SIZE = 200"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-2wTuktfkrg",
        "colab_type": "text"
      },
      "source": [
        "# **FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AylNfwfV0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_pickle(pickle_file):\n",
        "  with open(pickle_file, 'rb') as f :\n",
        "    return pickle.load(f)\n",
        "\n",
        "def show_image(image):\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  cv2_imshow(image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def seq_generator(image_embeddings, captions, SENTENCE_LEN, padding_element, NUM_WORDS, batch_size):\n",
        "\n",
        "  def pad_sequence(seq, seq_len, padding_element):\n",
        "    if len(seq) >= seq_len: return seq[0:seq_len] \n",
        "    else: return seq + [padding_element]*(seq_len-len(seq))\n",
        "\n",
        "  x1, x2, y = [], [], [] \n",
        "  n = 0\n",
        "\n",
        "  while True :\n",
        "    for i, caption in enumerate(captions):\n",
        "      n += 1 \n",
        "      seq = random.choice(caption)\n",
        "      for j in range(len(seq)):\n",
        "        inseq, outseq = seq[:j], seq[j] \n",
        "        x1.append(image_embeddings[i])\n",
        "        x2.append(pad_sequence(inseq, SENTENCE_LEN, padding_element))\n",
        "        y.append(to_categorical([outseq], NUM_WORDS)[0] )\n",
        "      if n == batch_size :\n",
        "        yield ([np.array(x1), np.array(x2)], np.array(y))\n",
        "        x1, x2, y = [], [], [] \n",
        "        n = 0\n",
        "\n",
        "def get_num_sentences(captions):\n",
        "  return len(captions) * 5\n",
        "\n",
        "def split_sentence(sentence):\n",
        "  return list(filter(lambda x : len(x) > 2 and x not in stop_words, re.split('\\W+', sentence.lower())))\n",
        "\n",
        "def get_max_len(captions):\n",
        "  maxlength = 0 \n",
        "  for caption in captions:\n",
        "    for sentence in caption:\n",
        "      maxlength = max(maxlength, len(sentence))\n",
        "  return maxlength\n",
        "\n",
        "def get_vocab(captions, vocab_size):\n",
        "  vocab = dict()\n",
        "  for caption in captions :\n",
        "    for sentence in caption:\n",
        "      for word in split_sentence(sentence):\n",
        "        if len(word) < 3 or word in stop_words: continue \n",
        "        if word[-1] == '.' : word = word[:-1]\n",
        "        vocab[word] = vocab.get(word, 0) + 1\n",
        "\n",
        "  vocab = [word[0] for word in sorted(vocab.items(), key = lambda item : item[1], reverse = True)][0: vocab_size-4] + [PAD, UNK, START, END]\n",
        "  word2ix = {word:index for index, word in enumerate(vocab)} \n",
        "  ix2word = {index:word for index, word in enumerate(vocab)} \n",
        "  return vocab, word2ix, ix2word\n",
        "\n",
        "def captions2captions(captions, word2ix):\n",
        "  new_captions = [] \n",
        "  for caption in captions : \n",
        "    new_caption = [] \n",
        "    for sentence in caption:\n",
        "      #there's a problem here, if a word ends with '.' it will be ignored while we ideally want to just erase the '.' and get the word\n",
        "      new_caption.append([word2ix[START]] + [word2ix[word] for word in split_sentence(sentence) if word in word2ix] + [word2ix[END]])\n",
        "    new_captions.append(new_caption)\n",
        "  return new_captions\n",
        "\n",
        "\n",
        "def build_model(SENTENCE_LEN, NUM_WORDS, WORD_EMBED_SIZE, LSTM_UNITS):\n",
        "  image_features = L.Input(shape = (2048,)) \n",
        "  densed_IF = L.Dense(256)(image_features) \n",
        "  densed_IF = L.Dense(WORD_EMBED_SIZE)(densed_IF)\n",
        "  initial_state = [densed_IF, densed_IF]\n",
        "\n",
        "  words = L.Input(shape = (SENTENCE_LEN,))\n",
        "  words_embeddings = L.Embedding(NUM_WORDS, WORD_EMBED_SIZE)(words) \n",
        "\n",
        "  lstm_output = L.LSTM(LSTM_UNITS)(inputs = words_embeddings, initial_state = initial_state) \n",
        "\n",
        "  decoded_words1 = L.Dense(512, activation = 'relu')(lstm_output) \n",
        "  decoded_words2 = L.Dense(1024, activation = 'relu')(decoded_words1)\n",
        "  final_output = L.Dense(NUM_WORDS, activation = 'softmax')(decoded_words2) \n",
        "\n",
        "  model = keras.Model(inputs = [image_features, words], outputs = final_output) \n",
        "  return model\n",
        "\n",
        "def download_data():\n",
        "\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-5AhtN3za59P6WsHBhVRw7Lonx4wk6xu' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-5AhtN3za59P6WsHBhVRw7Lonx4wk6xu\" -O train_image_features.pickle && rm -rf /tmp/cookies.txt\n",
        "  train_image_embeds = read_pickle('train_image_features.pickle') \n",
        "\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1--FpSwNWO9X8l5YneuTHcs--EtJlJZOP' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1--FpSwNWO9X8l5YneuTHcs--EtJlJZOP\" -O val_image_embeds.pickle && rm -rf /tmp/cookies.txt\n",
        "  val_image_embeds = read_pickle('val_image_embeds.pickle') \n",
        "\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-729Stj7PWEztvH-YVJ_nivo4QmGR-ro' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-729Stj7PWEztvH-YVJ_nivo4QmGR-ro\" -O train_captions.pickle && rm -rf /tmp/cookies.txt\n",
        "  train_captions = read_pickle('train_captions.pickle') \n",
        "\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-1WfbEjN052jaHSUb4h5J_t9BIgziSP3' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-1WfbEjN052jaHSUb4h5J_t9BIgziSP3\" -O val_captions.pickle && rm -rf /tmp/cookies.txt\n",
        "  val_captions = read_pickle('val_captions.pickle') \n",
        "\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-77wJhnWLCnvmBOvOFuQrAv_ekjE-ooa' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-77wJhnWLCnvmBOvOFuQrAv_ekjE-ooa\" -O train_image_fns.pickle && rm -rf /tmp/cookies.txt\n",
        "  train_image_fns = read_pickle('train_image_fns.pickle') \n",
        "\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-2HLbOGLT4E9V_IywjwNWBviyz49QjrY' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-2HLbOGLT4E9V_IywjwNWBviyz49QjrY\" -O val_image_fns.pickle && rm -rf /tmp/cookies.txt\n",
        "  val_image_fns = read_pickle('val_image_fns.pickle') \n",
        "\n",
        "  return train_image_embeds, val_image_embeds, train_captions, val_captions, train_image_fns, val_image_fns \n",
        "\n",
        "def get_CNN_model():\n",
        "  image_preprocessing = preprocess_input \n",
        "  base_cnnmodel = InceptionV3(include_top=False) \n",
        "  cnnmodel = L.GlobalAveragePooling2D()(base_cnnmodel.output)  \n",
        "  cnnmodel = keras.Model(base_cnnmodel.input, cnnmodel) \n",
        "  return cnnmodel, image_preprocessing \n",
        "\n",
        "def predict(model, cnn_model, image_preprocessing_func, imagepath, VOCAB, word2ix, ix2word):\n",
        "\n",
        "  def pad_sequence(seq, seq_len, padding_element):\n",
        "    if len(seq) >= seq_len: return seq[0:seq_len] \n",
        "    else: return seq + [padding_element]*(seq_len-len(seq))\n",
        "\n",
        "  image = img_to_array(load_img(imagepath) )\n",
        "  image4dim = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
        "  image_embeds = cnn_model(image_prepro(image4dim)) \n",
        "\n",
        "  result = [word2ix[START]] \n",
        "  current = result[0]\n",
        "  while len(result) < SENTENCE_LEN and current != word2ix[END] :\n",
        "    sen_embeds = np.array(pad_sequence(result, SENTENCE_LEN, word2ix[PAD]))\n",
        "    sen_embeds = np.expand_dims(sen_embeds, axis=0) \n",
        "    \n",
        "    in_seq = [np.array(image_embeds), np.array(sen_embeds)] \n",
        "    out_seq = model.predict(in_seq)[0] \n",
        "    current = word2ix[VOCAB[np.argmax(out_seq)]]\n",
        "    result += [current] \n",
        "   \n",
        "  \n",
        "  return [ix2word[item] for item in result]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-RYEd5Lrf6m",
        "colab_type": "text"
      },
      "source": [
        "# **CAPTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJCJWlzNfkOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture \n",
        "train_image_embeds, val_image_embeds, train_captions, val_captions, train_image_fns, val_image_fns = download_data() \n",
        "all_captions = train_captions + val_captions "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZw1Ljo2C7uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_WORDS = 5000\n",
        "SENTENCE_LEN = 20\n",
        "WORD_EMBED_SIZE = 200"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAmkKJh2gMa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "NUM_SENTENCES = get_num_sentences(train_captions) \n",
        "VOCAB, word2ix, ix2word = get_vocab(all_captions, vocab_size = NUM_WORDS) \n",
        "train_captions_ix = captions2captions(train_captions, word2ix)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEC57LPUOrfU",
        "colab_type": "text"
      },
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDDkjW2ajXpC",
        "colab_type": "text"
      },
      "source": [
        "## TRAIN & SAVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNyUTOrBv09b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "K.clear_session() \n",
        "cnn_model, image_prepro = get_CNN_model() \n",
        "model = build_model(SENTENCE_LEN, NUM_WORDS, WORD_EMBED_SIZE, LSTM_UNITS = 200) \n",
        "\n",
        "#scheduler = ExponentialDecay(initial_learning_rate= 1e-3, decay_rate = 0.93, decay_steps = 10000)\n",
        "opt = Adam(learning_rate = 0.0001)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = opt)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPVXyhT-1QMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "956a4d09-73d1-40b5-ade0-463de90c90da"
      },
      "source": [
        "init_epochs = 7\n",
        "second_epochs = 10\n",
        "\n",
        "BS = 50\n",
        "steps = NUM_SENTENCES // BS\n",
        "train_generator = seq_generator(train_image_embeds, train_captions_ix, SENTENCE_LEN, word2ix[PAD], NUM_WORDS, batch_size = BS)\n",
        "\n",
        "for epoch in range(init_epochs) :\n",
        "  model.fit(train_generator, epochs = 1, steps_per_epoch = steps, verbose = 1) \n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8278/8278 [==============================] - 229s 28ms/step - loss: 4.2457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMv63Om4KkcM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d2d3e5d5-2368-4f85-b2e1-79fa908196d9"
      },
      "source": [
        "second_opt = Adam(learning_rate = 0.0001)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = second_opt)\n",
        "\n",
        "for epoch in range(second_epochs):\n",
        "  model.fit(train_generator, epochs = 1, steps_per_epoch = steps, verbose = 1) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8278/8278 [==============================] - 227s 27ms/step - loss: 3.5752\n",
            "8278/8278 [==============================] - 225s 27ms/step - loss: 3.2902\n",
            "8278/8278 [==============================] - 225s 27ms/step - loss: 3.1330\n",
            "8278/8278 [==============================] - 225s 27ms/step - loss: 3.0273\n",
            "8278/8278 [==============================] - 224s 27ms/step - loss: 2.9491\n",
            "8278/8278 [==============================] - 224s 27ms/step - loss: 2.8833\n",
            "8278/8278 [==============================] - 225s 27ms/step - loss: 2.8304\n",
            "8278/8278 [==============================] - 225s 27ms/step - loss: 2.7816\n",
            "8278/8278 [==============================] - 225s 27ms/step - loss: 2.7422\n",
            "8278/8278 [==============================] - 225s 27ms/step - loss: 2.7061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fNDTOrGNwWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/drive/My Drive/image_caption_project/partial_model.h5'\n",
        "model.save_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76VYejYyjcoa",
        "colab_type": "text"
      },
      "source": [
        "## LOAD & PLAY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfdZih9gDCoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_WORDS = 5000\n",
        "SENTENCE_LEN = 20\n",
        "WORD_EMBED_SIZE = 200"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6IjoDz1NxXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/drive/My Drive/image_caption_project/partial_model.h5'\n",
        "\n",
        "K.clear_session() \n",
        "model = build_model(SENTENCE_LEN, NUM_WORDS, WORD_EMBED_SIZE, LSTM_UNITS = 200) \n",
        "model.load_weights(model_path) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHop_rLRDKNM",
        "colab_type": "text"
      },
      "source": [
        "# **PREDICT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN3uico1DNGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagepath = 'flower.jpg'\n",
        "res_sent = predict(model, cnn_model, image_prepro, imagepath, VOCAB, word2ix, ix2word)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z25UPKXY-wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cca7c69-0434-466f-b8aa-c33ae50a0641"
      },
      "source": [
        "print(res_sent)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['#START#', 'bench', 'sitting', 'grass', '#END#']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPVwWb8OZARF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}